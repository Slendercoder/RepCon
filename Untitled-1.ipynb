{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiantes/.local/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'es_core_news_sm' (3.1.0) requires spaCy v3.1 and is incompatible with the current spaCy version (2.3.7). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from nltk import Tree\n",
    "from nltk.tree import ParentedTree\n",
    "import es_core_news_sm\n",
    "import stanza\n",
    "from spacy_stanza import StanzaLanguage\n",
    "\n",
    "#nlp = es_core_news_sm.load()\n",
    "\n",
    "#nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_ + '-' + node.dep_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_ + '-' + node.dep_\n",
    "\n",
    "def to_nltk_tree1(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.tag_, [to_nltk_tree1(child) for child in node.children])\n",
    "    else:\n",
    "        return node.tag_\n",
    "\n",
    "def crear_arbol(texto):\n",
    "    document = nlp(texto)\n",
    "    jc = list(document.sents)[0]\n",
    "    arbol = to_nltk_tree1(jc.root)\n",
    "    # arbol = ParentedTree.convert(arbol)\n",
    "    arbol.pretty_print()\n",
    "    return arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec1(A):\n",
    "    if type(A) is nltk.Tree:\n",
    "        cadena = A.label() \n",
    "        for i, B in enumerate(A):\n",
    "            cadena += '(' + rec1(B) + ')'\n",
    "        return cadena\n",
    "    else:\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicacion(A, diccionario):\n",
    "    if type(A) is nltk.Tree:\n",
    "        funcion = diccionario[A.label()]\n",
    "        argumentos = [aplicacion(x, diccionario) for x in A]\n",
    "        return funcion(*argumentos)\n",
    "    else:\n",
    "        return diccionario[A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto, stopwords):\n",
    "#     token = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "#     tokens = token.tokenize(texto)\n",
    "#     lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    snlp = stanza.Pipeline(lang=\"es\")\n",
    "    nlp = StanzaLanguage(snlp)\n",
    "    texto = nlp(texto)\n",
    "    #lista_texto = texto.split()\n",
    "    lista = [token.lemma_ for token in texto]\n",
    "    lista = [x for x in lista if x not in stopwords]\n",
    "    return ' '.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b78a7dad6dc464aaa9d2cb3871c47d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 09:22:27 INFO: Downloading default packages for language: es (Spanish)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3337193e2c45d58d1ac48969e8d3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/es/default.zip:   0%|          | 0.00/566M [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "md5 for /home/estudiantes/stanza_resources/es/default.zip is 58e67356857d3b40cba98f68d1b26690, expected 1a63eaa21cad42f23d98a1e5c996814f",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1533cf1d181a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'es'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/resources/common.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(lang, model_dir, package, processors, logging_level, verbose, resources_url, resources_branch, resources_version, model_url, proxies)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;34mf'Downloading default packages for language: {lang} ({lang_name})...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         )\n\u001b[0;32m--> 427\u001b[0;31m         request_file(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;34mf'{url}/{resources_version}/{lang}/default.zip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'default.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/resources/common.py\u001b[0m in \u001b[0;36mrequest_file\u001b[0;34m(url, path, proxies, md5, raise_for_status)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_for_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0massert_file_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msort_processors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stanza/resources/common.py\u001b[0m in \u001b[0;36massert_file_exists\u001b[0;34m(path, md5)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mfile_md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mfile_md5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"md5 for %s is %s, expected %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_md5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_for_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: md5 for /home/estudiantes/stanza_resources/es/default.zip is 58e67356857d3b40cba98f68d1b26690, expected 1a63eaa21cad42f23d98a1e5c996814f"
     ]
    }
   ],
   "source": [
    "stanza.download('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 12:55:44 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-02-28 12:55:44 INFO: Use device: cpu\n",
      "2022-02-28 12:55:44 INFO: Loading: tokenize\n",
      "2022-02-28 12:55:44 INFO: Loading: mwt\n",
      "2022-02-28 12:55:44 INFO: Loading: pos\n",
      "2022-02-28 12:55:45 INFO: Loading: lemma\n",
      "2022-02-28 12:55:45 INFO: Loading: depparse\n",
      "2022-02-28 12:55:45 INFO: Loading: ner\n",
      "2022-02-28 12:55:46 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juan detestar maria\n",
      "  Gender=Masc|  \n",
      "  Number=Sing   \n",
      "       |         \n",
      "  VerbForm=Inf  \n",
      "       |         \n",
      "Gender=Fem|Numbe\n",
      "     r=Sing     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Gender=Masc|Number=Sing(VerbForm=Inf(Gender=Fem|Number=Sing))'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['a']\n",
    "texto = 'juan detesta a maria'\n",
    "texto = limpiar_texto(texto, stopwords)\n",
    "print(texto)\n",
    "arbol = crear_arbol(texto)\n",
    "rec1(arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {'camina-ROOT': lambda x: 'CAMINAR(' + str(x) + ')', \n",
    "               'juan-nsubj':'j',\n",
    "               'detesta-ROOT': lambda x, y: 'DETESTAR(' + str(x) + ',' + str(y) + ')', \n",
    "               'comer-ccomp': lambda x: 'COMER(' + str(x) + ')', \n",
    "               'maria-obj':'m',\n",
    "               'pizza-obj' : 'p'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DETESTAR(j,m)'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aplicacion(arbol, diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
