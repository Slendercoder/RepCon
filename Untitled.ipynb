{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/estudiantes/.local/lib/python3.8/site-packages (2.3.7)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.2.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy) (20.3)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (0.7.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy) (2.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/estudiantes/.local/lib/python3.8/site-packages (from spacy) (0.6.1)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (636 kB)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/estudiantes/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/estudiantes/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/estudiantes/.local/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Installing collected packages: catalogue, srsly, thinc, spacy\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.5\n",
      "    Uninstalling srsly-1.0.5:\n",
      "      Successfully uninstalled srsly-1.0.5\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 7.4.5\n",
      "    Uninstalling thinc-7.4.5:\n",
      "      Successfully uninstalled thinc-7.4.5\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 2.3.7\n",
      "    Uninstalling spacy-2.3.7:\n",
      "      Successfully uninstalled spacy-2.3.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy-stanza 0.2.5 requires spacy<3.0.0,>=2.1.0, but you have spacy 3.2.3 which is incompatible.\n",
      "es-core-news-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed catalogue-2.0.6 spacy-3.2.3 srsly-2.4.2 thinc-8.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiantes/.local/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'es_core_news_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from nltk import Tree\n",
    "from nltk.tree import ParentedTree\n",
    "import es_core_news_sm\n",
    "#import stanza\n",
    "#from spacy_stanza import StanzaLanguage\n",
    "\n",
    "#nlp = es_core_news_sm.load()\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "#snlp = stanza.Pipeline(lang=\"es\")\n",
    "#nlp = StanzaLanguage(snlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_ + '-' + node.dep_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_ + '-' + node.dep_\n",
    "\n",
    "    \n",
    "def to_nltk_tree1(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.tag_, [to_nltk_tree1(child) for child in node.children])\n",
    "    else:\n",
    "        return node.tag_\n",
    "\n",
    "    \n",
    "def crear_arbol(texto, nlp):\n",
    "    document = nlp(texto)\n",
    "    jc = list(document.sents)[0]\n",
    "    arbol = to_nltk_tree(jc.root)\n",
    "    # arbol = ParentedTree.convert(arbol)\n",
    "    arbol.pretty_print()\n",
    "    return arbol\n",
    "\n",
    "\n",
    "def rec1(A):\n",
    "    if type(A) is nltk.Tree:\n",
    "        cadena = A.label() \n",
    "        for i, B in enumerate(A):\n",
    "            cadena += '(' + rec1(B) + ')'\n",
    "        return cadena\n",
    "    else:\n",
    "        return A\n",
    "    \n",
    "    \n",
    "def aplicacion(A, diccionario):\n",
    "    if type(A) is nltk.Tree:\n",
    "        funcion = diccionario[A.label()]\n",
    "        argumentos = [aplicacion(x, diccionario) for x in A]\n",
    "        return funcion(*argumentos)\n",
    "    else:\n",
    "        return diccionario[A]\n",
    "\n",
    "    \n",
    "def limpiar_texto(texto, stopwords):\n",
    "#     token = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "#     tokens = token.tokenize(texto)\n",
    "#     lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    snlp = stanza.Pipeline(lang=\"es\")\n",
    "    nlp = StanzaLanguage(snlp)\n",
    "    texto = nlp(texto)\n",
    "    #lista_texto = texto.split()\n",
    "    lista = [token.lemma_ for token in texto]\n",
    "    lista = [x for x in lista if x not in stopwords]\n",
    "    return ' '.join(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {'camina-ROOT': lambda x: 'CAMINAR(' + str(x) + ')',\n",
    "               'detesta-ROOT': lambda x, y: 'DETESTAR(' + str(x) + ',' + str(y) + ')', \n",
    "               'viaja-ROOT' : lambda x,y,z,w: 'VIAJAR(' + str(x) + ',' + str(y) + ',' + str(z) + ',' + str(w) + ')',\n",
    "               'tener-ROOT': lambda x, y: 'TENER(' + str(x) + ',' + str(y) + ')',\n",
    "               'comer-ccomp': lambda x: 'COMER(' + str(x) + ')',\n",
    "               'juan-nsubj':'j1',\n",
    "               'maria-obj':'m1',\n",
    "               'pizza-obj' : 'p1',\n",
    "               'laptop-obj': 'l1',\n",
    "              'bogota-obj': 'b2',\n",
    "              'medellin-obj': 'm2',\n",
    "              'martes-obj': 'm3',\n",
    "              'miercoles-obj': 'c3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           viaja-ROOT                        \n",
      "     __________|_______________________       \n",
      "juan-nsubj bogota-obj medellin-obj martes-obj\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'viaja-ROOT(juan-nsubj)(bogota-obj)(medellin-obj)(martes-obj)'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['a']\n",
    "texto = 'juan viaja bogota medellin martes '\n",
    "#texto = limpiar_texto(texto, stopwords)\n",
    "arbol1 = crear_arbol(texto,nlp)\n",
    "rec1(arbol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VIAJAR(j1,b2,m2,m3)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aplicacion(arbol1, diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tener-ROOT           \n",
      "     __________|__________       \n",
      "juan-nsubj            laptop-obj\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tener-ROOT(juan-nsubj)(laptop-obj)'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['a']\n",
    "texto = 'juan tener laptop'\n",
    "#texto = limpiar_texto(texto, stopwords)\n",
    "arbol2 = crear_arbol(texto,nlp)\n",
    "rec1(arbol2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TENER(j1,l1)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aplicacion(arbol2, diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a']\n",
    "texto = 'si juan está en bogota, entonces el laptop está en bogota'\n",
    "#texto = limpiar_texto(texto, stopwords)\n",
    "arbol3 = crear_arbol(texto,nlp)\n",
    "rec1(arbol3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encontro si\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Conjuncion\n",
      "Antecedente:  ['juan', 'tiene', 'una', 'laptop', 'y', 'juan', 'está', 'en', 'Bogotá']\n",
      "Consecuente:  ['la', 'laptop', 'está', 'en', 'Bogotá']\n"
     ]
    }
   ],
   "source": [
    "# Función para condicionales\n",
    "def props(texto):\n",
    "    documento = nlp(texto)\n",
    "    palabras = [t.orth_ for t in documento]\n",
    "    conjuncion = False\n",
    "    coma = False\n",
    "    entonces = True\n",
    "    for i,token in enumerate(documento):\n",
    "        if token.tag_ == \"SCONJ\":\n",
    "            ind_si = i\n",
    "            conjuncion = True\n",
    "        if conjuncion:\n",
    "            if token.tag_ == \"PUNCT\" and token.orth_ == \",\":\n",
    "                ind_coma = i\n",
    "                coma = True\n",
    "            if token.tag_ == \"ADV\" and token.orth_ == \"entonces\":\n",
    "                ind_ent = i\n",
    "                entonces = True\n",
    "    if conjuncion and (ind_coma == ind_ent - 1):\n",
    "        print(\"Antecedente: \", palabras[ind_si + 1 : ind_coma])\n",
    "        print(\"Consecuente: \", palabras[ind_ent +1:])       \n",
    "    \n",
    "    \n",
    "txt = \"Si juan tiene una laptop y juan está en Bogotá, entonces la laptop está en Bogotá\"\n",
    "#txt = \"Si Juan está en Bogotá\"\n",
    "props(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
